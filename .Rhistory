cbind(emp.data,Address=y)
y<-c("jodhpur","Delhi","lucknow","Amethi","kanpur","Bihar")
cbind(emp.data,Address=y)
y<-c("jodhpur","Delhi","lucknow","Amethi","kanpur","Bihar")
cbind(emp.data,Address=y)
x<-list(6,"Tushar",452.6,"2023-07-01")
rbind(emp.data,x)
y<-c("jodhpur","Delhi","lucknow","Amethi","kanpur","Bihar")
cbind(emp.data,Address=y)
y<-c("jodhpur","Delhi","lucknow","Amethi","kanpur","Bihar")
cbind(emp.data,Address=y)
y<-c("jodhpur","Delhi","lucknow","Amethi","kanpur")
cbind(emp.data,Address=y)
x<-list(6,"Tushar",452.6,"2023-07-01")
rbind(emp.data,x)
y<-c("jodhpur","Delhi","lucknow","Amethi","kanpur")
cbind(emp.data,Address=y)
print(summary(emp.data))
source("C:/Users/abc/OneDrive/Documents/R programming/R_programming_basic.R")
source("C:/Users/abc/OneDrive/Documents/R programming/R_programming_basic.R")
source("C:/Users/abc/OneDrive/Documents/R programming/R_programming_basic.R")
source("C:/Users/abc/OneDrive/Documents/R programming/R_programming_basic.R")
source("C:/Users/abc/OneDrive/Documents/R programming/R_programming_basic.R")
source("C:/Users/abc/OneDrive/Documents/R programming/R_programming_basic.R")
source("C:/Users/abc/OneDrive/Documents/R programming/R_programming_basic.R")
source("C:/Users/abc/OneDrive/Documents/R programming/R_programming_basic.R")
is.factor(dir)
dir<-c("north","south","west","East")
is.factor(dir)
dir<-c("north","south","west","East")
is.factor(dir)
factor(dir)
dir<-c("north","south","west","north")
is.factor(dir)
factor(dir)
factor(dir,levels = c("north","south","west","East"))
factor(dir,levels = c("north","south","west","East"),labels = "N","S","W","E")
factor(dir,levels = c("north","south","west","East"),labels = c("N","S","W","E"))
factor(dir,levels = c("north","south","west","East"),exclude = "North" )
factor(dir,levels = c("north","south","west","East"),labels = c("N","S","W","E"))
factor(dir,levels = c("north","south","west","East"),exclude = "North" )
factor(dir,levels = c("north","south","west","East"),labels = c("N","S","W","E"))
factor(dir,levels = c("north","south","west","East"),exclude = "north" )
v1<-gl(3,4,labels = c("ram","mohan","sohan"))
v1
dir<-c("north","south","west","East")
data<-factor(dir)
data
data[c(2,4)]
data[-1]
data[2]<-"east"
v1<-gl(3,4,labels = c("ram","mohan","sohan"))
v1
dir<-c("north","south","west","East")
data<-factor(dir)
data
data[c(2,4)]
data[-1]
data[2]<-"east"
print(num.data)
gc()
num.data<-data.frame(
x1 = c("Abhi","Alkesh","gaurav","ram"),
x1 = c(1:4),
x1 = c('a','b','c','d'),
x2 = " ",
x3 = NA
stringsAsFactors = FALSE
num.data<-data.frame(
x1 = c("Abhi","Alkesh","gaurav","ram"),
x1 = c(1:4),
x1 = c('a','b','c','d'),
x2 = " ",
x3 = c(NA),
stringsAsFactors = FALSE
)
print(num.data)
print(num.data)
str(num.data)
names(num.data)
names(num.data)<-c("c1","c2","c3","c4","c5")
print(num.data)
print(num.data)
colnames(num.data)
colnames(num.data)
colnames(num.data)<-paste0("col",1:ncol(num.data))
colnames(num.data)
num.data[1:5,]
num.data[1:5,1:3]
# for cheking Nan value function
rowsum(num.data)
# for cheking Nan value function
rowsum(1:5)
# for cheking Nan value function
rowSums(num.data)
# for cheking Nan value function
rowSums(num.data)
num.data[num.data = " "] <-10
# for cheking Nan value function
num.data[is.na(num.data)] <- 10
num.data[num.data == ""] <- 10
rowSums(num.data)
num.data<-data.frame(
x1 = c(4:9),
x1 = c(1:4),
x1 = c('a','b','c','d'),
x2 = " ",
x3 = c(NA),
stringsAsFactors = FALSE
)
num.data<-data.frame(
x1 = c("Abhi","Alkesh","gaurav","ram"),
x1 = c(1:4),
x1 = c('a','b','c','d'),
x2 = " ",
x3 = c(NA),
stringsAsFactors = FALSE
)
print(num.data)
str(num.data)
names(num.data)<-c("c1","c2","c3","c4","c5")
print(num.data)
colnames(num.data)
colnames(num.data)<-paste0("col",1:ncol(num.data))
colnames(num.data)
num.data[1:5,1:3] # data slicing
# for cheking Nan value function
num.data[is.na(num.data)] <- 10
num.data[num.data == ""] <- 10
rowSums(num.data)
row_sums <- rowSums(num.data, na.rm = TRUE)
row_sums <- rowSums(num.data)
row_sums <- rowSums(num.data)
num.data<-data.frame(
x1 = c(1:4),
x1 = c(1:4),
x1 = c(1:4),
x2 = " ",
x3 = c(NA),
stringsAsFactors = FALSE
)
print(num.data)
str(num.data)
names(num.data)<-c("c1","c2","c3","c4","c5")
print(num.data)
colnames(num.data)
colnames(num.data)<-paste0("col",1:ncol(num.data))
colnames(num.data)
num.data[1:5,1:3] # data slicing
# for cheking Nan value function
num.data[is.na(num.data)] <- 10
num.data[num.data == ""] <- 10
row_sums <- rowSums(num.data)
list3<-list(c("ram","Alkesh","Shukla"),c(78,56,98),list("btech","bsc","bcom"))
list3
x<-1:10
any(x>5)
any(x>15)
# array_name<-array(data,dim=())
v1<-c(1,4,5)
v2<-c(10,20,30,40,50,60)
v3<-array(c(v1,v2),dim=c(3,3,4))
print(v3)
# array_name<-array(data,dim=())
v1<-c(1,4,5)
v2<-c(10,20,30,40,50,60)
v3<-array(c(v1,v2),dim=c(3,3,4),byrow=T)
# array_name<-array(data,dim=())
v1<-c(1,4,5)
v2<-c(10,20,30,40,50,60)
v3<-array(c(v1,v2),byrow=True,dim=c(3,3,4))
# array_name<-array(data,dim=())
v1<-c(1,4,5)
v2<-c(10,20,30,40,50,60)
v3<-array(c(v1,v2),dim=c(3,2,2))
print(v3)
dir<-c("north","south","west","East") # levels are not repeated if two values are same then it write only one times
is.factor(dir)
factor(dir)
# creating a data frame
emp.data<-data.frame(
employee_id = c(1:5),
employee_name= c("Alkesh","Devesh","Shibu","Deepu","gaurav"),
sal = c(523.65,5421.5,458.6,2569.0,2154.6),
starting_date = as.Date(c("2023-06-25","2023-06-05","2023-06-15","2023-06-14","2023-06-1")),
stringsAsFactors = FALSE
)
# print the data frame
print(emp.data)
str(emp.data)
f1<-data.frame(emp.data$employee_name,emp.data$sal)
f1
f2<-emp.data[3:5,]
f2
f3<-emp.data[c(2,3),c(1,4)]
f3
view(iris)
iris
view(iris)
install.packages("install.packages("utils")")
install.packages("utils")
head(iris)
head(iris)
head(iris,10)
tail(iris)
table(iris$Sepal.Length)
table(iris$Species)
library(dplyr)
install.packages("dplyr")
library(dplyr)
view(iris)
install.packages("utilsIPEA")
view(iris)
library(utils)
view(IRIS)
view(iris)
head(iris)
getwd()
setwd()
setwd(C:\Users\abc\OneDrive\Documents)
setwd("C:\Users\abc\OneDrive\Documents")
setwd("C:\\Users\\abc\\OneDrive\\Documents")
any(grepl("xlsx",installed.packages()))
install.packages("xlsx")
install.packages("xlsx")
library("dplyr")
any(grepl("dplyr",installed.packages()))
data<-c(418,428,431,420,412,425,423,433,417,420,410,431,429,425)
sort(data)
summary(data)
count(data)
length(data)
sd(data)
cv <- sd(data)/mean(data)
cv<-cv*100
cv
before -> c(172:220,10)
before -> c(rand(172:220,10))
before -> c(randu(172:220,10))
install.packages("ggpubr")
my_data <- data.frame(
BeforeTreatment= c(85,70,40,65,80,75,55,20),
AfterTreatment = c(75,50,50,40,20,65,40,25)
)
print(my_data)
wilcox.test(my_data$BeforeTreatment,my_data$AfterTreatment,paired = TRUE)
my_data <- data.frame(
BeforeTreatment= c(85,70,40,65,80,75,55,20),
AfterTreatment = c(75,50,50,40,20,65,40,25)
)
print(my_data)
wilcox.test(my_data$BeforeTreatment,my_data$AfterTreatment,paired = TRUE)
my_data <- data.frame(
BeforeTreatment= c(85,70,40,65,80,75,55,20),
AfterTreatment = c(75,50,50,40,20,65,40,25)
)
# Perform Shapiro-Wilk test for 'BeforeTreatment'
shapiro.test(my_data$BeforeTreatment)
# Perform Shapiro-Wilk test for 'AfterTreatment'
shapiro.test(my_data$AfterTreatment)
print(my_data)
# non Parametric test
wilcox.test(my_data$BeforeTreatment,my_data$AfterTreatment,paired = TRUE)
if(!require(psych)){install.packages("psych")}
if(!require(BSDA)){install.packages("BSDA")}
if(!require(DescTools)){install.packages("DescTools")}
Input =("
Cartoon  Time  Student  Likert
Pooh      1     a        1
Pooh      1     b        4
Pooh      1     c        3
Pooh      1     d        3
Pooh      1     e        3
Pooh      1     f        3
Pooh      1     g        4
Pooh      1     h        3
Pooh      1     i        3
Pooh      1     j        3
Pooh      2     a        4
Pooh      2     b        5
Pooh      2     c        4
Pooh      2     d        5
Pooh      2     e        4
Pooh      2     f        5
Pooh      2     g        3
Pooh      2     h        4
Pooh      2     i        3
Pooh      2     j        4
")
Data = read.table(textConnection(Input),header=TRUE)
library(psych)
library(psych)
headTail(Data)
str(Data)
library(MASS)
library(gginference)
help(Boston)
attach(Boston)
summary(dis)
#Plots to check the normality of the data
par(mfrow=c(2,2))
plot(dis)
hist(dis, main= "Histogram of number of Rooms")
qqnorm(dis, main= "QQ-plot for number of Rooms")
qqline(dis)
boxplot(dis)
# Non parametric test
shapiro.test(dis) # If p-value (< 0.05), not normally distributed.
#Just do a test with t-test
t.test(dis, mu=3.7)
ggttest(t.test(dis,mu=3.7))
wilcox.test(dis, mu=3.7, exact = F, paired = F)
wilcox.test(dis, mu = 3.7, alternative="less")
wilcox.test(dis, mu=3.7, alternative= "greater")
#if p-value < 0.05, Reject H0
#if p-value < 0.05, Reject H0
#if p-value > 0.05, do not reject H0
#if p-value < 0.05, Reject H0
#if p-value > 0.05, do not reject H0
#if p-value < 0.05, Reject H0
#if p-value > 0.05, do not reject H0
# k means clustring
library(factoextra)
install.packages("factoextra")
# k means clustring
library(factoextra)
data("USArrests")
view(USArrests)
View(USArrests)
df<-scale(USArrests)
head(df,n=5)
km<-Kmeans(df,center=4,iter.max=10,nstart=1)
km<-kmeans(df,center=4,iter.max=10,nstart=1)
km
dd<-cbind(df,cluster=km$cluster)
dd
head(dd)
library(factoextra)
fviz_nbclust(df,kmeans,method = "wss") +
geom_vline(xintercept = 4,linetype=2)
fviz_nbclust(df,kmeans,method = "silhoutte") +
geom_vline(xintercept = 4,linetype=2)
fviz_nbclust(df,kmeans,method = "silhouette") +
geom_vline(xintercept = 4,linetype=2)
fviz_cluster(km,data = df)
View(km)
View(my_data)
View(my_data)
View(dd)
View(df)
pamResult <- pam(df,k=2)
pamResult <- pam(df,k=2)
install.packages("cluster")
install.packages("cluster")
library(cluster)
## pam clustering
pamResult <- pam(df,k=2)
pamResult
head(cars)
str(cars)
plot(x=cars$speed,y=cars$dist,main="dist ~ speed")
car(cars$speed,cars$dist)
cars(cars$speed,cars$dist)
cor(cars$speed,cars$dist)
linearModel <- lm(dist~speed,data=cars)
print(linearModel)
summary(linearModel)
summary(linearModel)
dbline(linearModel,col="green")
abline(linearModel,col="green")
T_data <- data.frame(speed = 25)
predicted_dist<-predict(linearizeMlist,T_data)
predicted_dist<-predict(linearModel,T_data)
print(predicted_dist)
set_speed(100)
trainingRowIndex=sample(1,nrow(cars),0.8*nrows(cars))
set.speed(100)
set.seed(100)
trainingRowIndex<-sample(1,nrow(cars),0.8*nrows(cars))
trainingRowIndex<-sample(1,nrow(cars),0.8*nrow(cars))
trainingData<-cars[trainingRowIndex,]
testData<-cars[trainingRowIndex,]
print(trainingData)
View(testData)
print(testData)
linearModel <- lm(dist~speed,data=cars)
predicted_dist<-predict(linearModel,T_data)
print(predicted_dist)
summary(predicted_dist)
summary(linearModel)
setwd("C://Users//abc//OneDrive//Documents//R programming//Road_safety_Project")
stores<-read.csv("Road_Safety_Data _Accidents_2019.csv");  # Corrected file name
print(ncol(stores))  # 32
print(nrow(stores))  # 117536
# Print All the column names
column_names <- colnames(stores)
print(column_names)
####################################################################################
# Cleaning the data
if (!requireNamespace("dplyr", quietly = TRUE)) {
install.packages("dplyr")
}
if (!requireNamespace("mice", quietly = TRUE)) {
install.packages("mice")
}
library(dplyr)
library(mice)
# Create a copy of the dataset for cleaning
cleaned_data <- stores
# Finding NaN values in each column
for (col in column_names) {
print(col)
print(sum(is.na(cleaned_data[[col]])))
}
# Remove rows with missing values
cleaned_data <- na.omit(cleaned_data)
print(ncol(cleaned_data))  # 32
print(nrow(cleaned_data))  # 117508
# Re-check missing values after imputation/removal
for (col in column_names) {
print(col)
print(sum(is.na(cleaned_data[[col]])))
}
head(cleaned_data)
# Summary statistics after cleaning
summary_stats_cleaned <- summary(cleaned_data)
print(summary_stats_cleaned)
# Identify categorical and numerical columns
categorical_columns <- sapply(cleaned_data, is.factor)
numerical_columns <- sapply(cleaned_data, is.numeric)
# Print the results
cat("Categorical Columns:\n")
print(names(cleaned_data[categorical_columns]))
cat("\nNumerical Columns:\n")
print(names(cleaned_data[numerical_columns]))
if (!requireNamespace("lubridate", quietly = TRUE)) {
install.packages("lubridate")
}
library(lubridate)
# Convert the 'Date' column to a Date type
cleaned_data$Date <- as.Date(cleaned_data$Date, format = "%d/%m/%Y")
# Create a time series plot
library(ggplot2)
ggplot(cleaned_data, aes(x = factor(month(Date, label = TRUE)), fill = factor(Accident_Severity))) +
geom_bar(position = "stack") +
labs(title = "Distribution of Accidents Over Months",
x = "Month",
y = "Number of Accidents",
fill = "Severity") +
scale_x_discrete(name = "Month") +
scale_fill_discrete(name = "Severity",
labels = c("Slight", "Serious", "Fatal"))
########################################################################
# Analize the Accident happen on the map
if (!requireNamespace("leaflet", quietly = TRUE)) {
install.packages("leaflet")
}
print(ncol(cleaned_data))  # 32
print(nrow(cleaned_data))  # 117508
# Re-check missing values after imputation/removal
for (col in column_names) {
print(col)
print(sum(is.na(cleaned_data[[col]])))
}
head(cleaned_data)
# Summary statistics after cleaning
summary_stats_cleaned <- summary(cleaned_data)
print(summary_stats_cleaned)
# Identify categorical and numerical columns
categorical_columns <- sapply(cleaned_data, is.factor)
numerical_columns <- sapply(cleaned_data, is.numeric)
# Print the results
cat("Categorical Columns:\n")
print(names(cleaned_data[categorical_columns]))
cat("\nNumerical Columns:\n")
print(names(cleaned_data[numerical_columns]))
if (!requireNamespace("lubridate", quietly = TRUE)) {
install.packages("lubridate")
}
library(lubridate)
# Convert the 'Date' column to a Date type
cleaned_data$Date <- as.Date(cleaned_data$Date, format = "%d/%m/%Y")
# Create a time series plot
library(ggplot2)
ggplot(cleaned_data, aes(x = factor(month(Date, label = TRUE)), fill = factor(Accident_Severity))) +
geom_bar(position = "stack") +
labs(title = "Distribution of Accidents Over Months",
x = "Month",
y = "Number of Accidents",
fill = "Severity") +
scale_x_discrete(name = "Month") +
scale_fill_discrete(name = "Severity",
labels = c("Slight", "Serious", "Fatal"))
########################################################################
# Analize the Accident happen on the map
if (!requireNamespace("leaflet", quietly = TRUE)) {
install.packages("leaflet")
}
library(leaflet)
# Create a leaflet map
accident_map <- leaflet(data = cleaned_data) %>%
addTiles() %>%
addCircleMarkers(
lng = ~Longitude,
lat = ~Latitude,
radius = 1,
color = "red",
fillOpacity = 0.7,
popup = paste("Severity: ", cleaned_data$Accident_Severity)
)
# Display the map
accident_map
